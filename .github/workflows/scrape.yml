name: Real Estate Scraper
on:
  schedule:
    - cron: '0 */4 * * *'  # Every 4 hours
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-22.04
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          path: 'repo'

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20.x
          cache: 'npm'
          cache-dependency-path: 'repo/scripts/package-lock.json'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libnss3 libxss1 libasound2 libgbm1 \
            libdrm2 libxkbcommon0 libatk1.0-0 \
            libatk-bridge2.0-0 libx11-xcb1 \
            libxcomposite1 libxdamage1 libxfixes3 \
            libxrandr2 libxv1 xvfb

      - name: Install project dependencies
        working-directory: ./repo/scripts
        run: |
          npm install --prefix . puppeteer-core@latest @sparticuz/chromium@latest \
            tough-cookie@latest axios-cookiejar-support@latest firebase-admin@latest \
            cheerio@latest axios@latest
          npm cache clean --force

      - name: Run scraper
        working-directory: ./repo/scripts
        env:
          FIREBASE_CREDENTIALS: ${{ secrets.FIREBASE_CREDENTIALS }}
          FIREBASE_DB_URL: ${{ secrets.FIREBASE_DB_URL }}
          NODE_OPTIONS: "--max-old-space-size=3072"
        run: |
          # Start virtual display and scraper with cleanup
          Xvfb :99 -screen 0 1920x1080x24 -ac +extension GLX +render -noreset > /dev/null 2>&1 &
          export DISPLAY=:99
          
          # Run with timeout and proper cleanup
          timeout --kill-after=5m 25m node scraper.js || EXIT_CODE=$?
          
          # Force cleanup
          pkill -f chromium || true
          pkill -f Xvfb || true
          exit ${EXIT_CODE:-0}